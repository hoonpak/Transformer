{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "import info\n",
    "from data import CustomDataset, collate_fn\n",
    "from layers import EmbeddingWithPosition, EncoderLayer, DecoderLayer\n",
    "from sublayers import MultiHeadAttention, LayerLorm, PositionWiseFeedForward\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"../data/ende_WMT14_Tokenizer.json\"\n",
    "tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data tokenizing & loading: 2737it [00:00, 4636.18it/s]\n"
     ]
    }
   ],
   "source": [
    "src_train_data_path = \"../data/test/test_en.txt\"\n",
    "tgt_train_data_path = \"../data/test/test_de.txt\"\n",
    "training_dataset = CustomDataset(tokenizer=tokenizer, src_path=src_train_data_path, tgt_path=tgt_train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=training_dataset, batch_size=6, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data, tgt_data, src_len, tgt_len = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 42])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 42])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = info.base_hyper_params['d_model']\n",
    "shared_parameter = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model, padding_idx=info.PAD)\n",
    "emb_layer = EmbeddingWithPosition(vocab_size=vocab_size, pos_max_len=info.max_len, embedding_dim=info.base_hyper_params['d_model'],\n",
    "                                  drop_rate=info.base_hyper_params['dropout_rate'], shared_parameter=shared_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = emb_layer(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttention(head=8, d_model=d_model, d_k=info.base_hyper_params['d_k'], d_v=info.base_hyper_params['d_v'], is_masked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(x):\n",
    "    mask = torch.zeros(x.shape).to(info.device)\n",
    "    mask[x != 0] = 1. #N, L -> padding = 0, others = 1\n",
    "    mask_output = (torch.bmm(mask.unsqueeze(2), mask.unsqueeze(1)) == 0) #N, L, L\n",
    "    return mask, mask_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_mask, mask_info = get_mask(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = mha(emb, emb, emb, mask_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_connection = attn+emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-43.6471,   6.5885,  14.8586,  ...,  43.5617, -28.3112,  -6.9557],\n",
       "        [-14.7832, -37.1398,  13.9888,  ...,   8.8846,  -3.9687,   0.1097],\n",
       "        [ 12.4530,  11.3051,  -3.7756,  ...,   1.7943,  -4.7080,  23.5679],\n",
       "        ...,\n",
       "        [  9.7276, -20.4963, -42.4083,  ..., -11.8166, -19.7441, -47.0385],\n",
       "        [  3.2305,  23.4806,  14.3141,  ...,  10.5617,  -1.6362, -25.9419],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_connection[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_layer = LayerLorm(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_input = ln_layer(residual_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.inner_layer = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.outer_layer = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x, mask_info):\n",
    "        \"\"\"\n",
    "        **INPUT SHAPE**\n",
    "        x -> N, L, d_model\n",
    "        \"\"\"\n",
    "        mask_info = (mask_info == 0)\n",
    "        inner_output = self.relu(self.inner_layer(x).masked_fill(mask_info.unsqueeze(-1), 0))\n",
    "        outer_output = self.outer_layer(inner_output).masked_fill(mask_info.unsqueeze(-1), 0) #N, L, d_model\n",
    "        return outer_output\n",
    "    \n",
    "    def initialization(self):\n",
    "        nn.init.xavier_uniform_(self.inner_layer.weight)\n",
    "        nn.init.xavier_uniform_(self.outer_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWFFN_layer = PositionWiseFeedForward(d_model=d_model, d_ff=info.base_hyper_params['d_ff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_output = PWFFN_layer(ff_input, pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pad_mask[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2204e-01, -5.8269e-03, -1.1710e-01,  ..., -2.0872e-01,\n",
       "           5.3894e-02,  4.2081e-01],\n",
       "         [-2.6326e-01, -1.4075e-01,  9.9380e-02,  ...,  1.0107e-01,\n",
       "          -2.3084e-02,  3.9233e-01],\n",
       "         [-9.9831e-03,  5.6520e-01, -3.6336e-01,  ..., -1.9493e-01,\n",
       "          -2.3575e-01,  3.2691e-01],\n",
       "         ...,\n",
       "         [-3.0033e-01,  1.1433e-01, -2.2971e-01,  ..., -4.5300e-01,\n",
       "           2.2035e-01,  2.7764e-01],\n",
       "         [ 2.3948e-03,  2.9507e-01, -2.6200e-01,  ..., -1.3607e-01,\n",
       "           1.2082e-01,  2.4062e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.8747e-03, -1.2472e-01, -1.1271e-01,  ..., -1.4071e-02,\n",
       "           2.5923e-01,  2.5664e-01],\n",
       "         [-4.4890e-01, -2.5148e-01, -1.5256e-02,  ...,  8.1923e-02,\n",
       "          -7.6544e-02, -4.1019e-03],\n",
       "         [-2.7214e-01, -3.9339e-01, -4.2240e-01,  ..., -1.6787e-01,\n",
       "           2.4117e-01, -1.5117e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.4119e-02, -1.3513e-01, -2.0549e-01,  ...,  5.0976e-03,\n",
       "           3.5773e-01,  4.2149e-01],\n",
       "         [ 2.2946e-01, -1.0562e-01,  9.0700e-02,  ...,  1.0553e-01,\n",
       "           1.9828e-01,  1.0107e-01],\n",
       "         [-2.7247e-04, -3.2645e-01,  3.3384e-01,  ..., -2.6556e-01,\n",
       "           3.2802e-02, -1.0226e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-5.6911e-02, -1.4656e-01, -2.0796e-01,  ..., -1.3239e-01,\n",
       "          -6.2091e-03,  3.4074e-01],\n",
       "         [ 5.8495e-04,  1.0275e-01, -2.6577e-01,  ..., -1.3069e-03,\n",
       "           2.9791e-01,  3.5019e-02],\n",
       "         [-9.8967e-02, -1.4227e-01, -3.3477e-01,  ...,  9.7304e-03,\n",
       "           1.5038e-01, -9.0400e-02],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 4.6256e-02, -1.7303e-01, -9.4327e-02,  ..., -1.0758e-01,\n",
       "           2.6814e-01,  3.1704e-01],\n",
       "         [-8.2812e-02,  1.9258e-01,  2.2111e-02,  ..., -1.7521e-01,\n",
       "          -1.4522e-01,  2.3092e-02],\n",
       "         [-3.8499e-01, -1.3444e-01, -4.4108e-01,  ..., -8.5464e-02,\n",
       "          -1.3216e-01, -1.3262e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 1.2361e-01, -5.5763e-02, -1.6204e-01,  ..., -2.0784e-01,\n",
       "          -2.0904e-02,  3.2337e-01],\n",
       "         [-1.9457e-01, -1.4090e-01,  4.2310e-01,  ...,  2.5936e-01,\n",
       "          -4.9277e-02,  1.6569e-02],\n",
       "         [ 3.1009e-01,  1.1422e-01, -3.2016e-01,  ..., -2.2479e-01,\n",
       "           6.4748e-02,  2.3308e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0378,  0.2440, -0.1261,  ..., -0.0192, -0.2499, -0.0563],\n",
       "        [ 0.0783, -0.0004, -0.1130,  ..., -0.0748, -0.2160,  0.0278],\n",
       "        [-0.1758, -0.1294,  0.1887,  ..., -0.2898, -0.0820, -0.1759],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_output.masked_fill((ff_input == 0), 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
